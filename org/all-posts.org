#+hugo_base_dir: ../
#+seq_todo: TODO NEXT IN-PROGRESS DONE
#+STARTUP: overview

* DONE How I Org, A Software Engineer's Process                        :productivity:personal_process:
CLOSED: [2022-08-10 Wed 20:56]
:PROPERTIES:
:EXPORT_FILE_NAME: how-i-org
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '(Emacs "Org-mode")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "Emacs and Org-mode to track work, improve flow, and reduce (cognitive) stress"
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :images '("https://rm.rmdashrf.net/ox-hugo/task-state-cover.png")
:END:
:LOGBOOK:
- State "DONE"       from "TODO"       [2022-08-10 Wed 20:56]
:END:

** How I Org
I've encountered a half dozen or so personal productivity, task management, organization and motivation systems. (I will spare the list.) The latest I've read is David Allen's [[https://gettingthingsdone.com/][Getting Things Done]]. Having been there and done this, I read Allen's book with a "Just take me to the algorithm" mentality.

Also, I create software for living. Software development is an occupation that is both creative and technical. It's also a craft that is mostly performed at a computer and is now more virtual than ever. A lot of text in /Getting Things Done/ covers tools and techniques that support the algorithm, but are incidental: there are many ways to implement, track, and execute Allen's techniques. A salesperson's needs here are different than a manager's, are different than a software engineer's, and so on.

My own personal organization needs are nearly full-virtual. Either I'm in a virtual meeting, preparing for one, working on tasks from one, or---and what I do best---designing and writing code and building software products. And finally, I spend as much time as possible in the Emacs editor. There are many, many code editors and IDEs out there.  Yet once you've paid the admittedly steep learning curve for Emacs, it's the most effective "flow tool" I know of. What I do in Emacs, including this very text, I can get lost in, which means maximum productivity.

By the way, I do not mash up personal todos with my work as GTD encourages. I prefer a simpler in->due?->done for this part of my life. For personal work I use [[https://todoist.com/][Todoist]] for it's clean UX, mobile app, and sync across devices. Todoist recently added [[https://todoist.com/kanban-board][Kanban boards,]] so I may toy with a GTD-esque flow sans Emacs (which is a fiddly challenge to sync across devices.) That notwithstanding, I'll continue with my Emacs setup.

*** Why Emacs?
I admit, I've got years of Emacs key bindings in my fingers. But like playing the piano, practice makes plenty good. More keyboard, less mousing around many windows lends to good flow. I can now capture meeting notes, reference tidbits, fleeting ideas, and so on, with confidence I can forget them now, find them later, and fold follow ups into todo lists and projects plans.

*** References
The following works were highly influential in my own productivity thinking and, of course, this article. 
- [[https://gettingthingsdone.com/][Getting Things Done]] by David Allen: This highly popular "work of the day" got me re-thinking about personal productivity again, and tweaking some of my own practice as a result.
- [[https://www.researchgate.net/publication/222552899_Getting_Things_Done_The_Science_Behind_Stress-Free_Productivity][Getting Things Done: The Science Behind Stress-Free Productivity]] by Francis Heylighen and Clément Vidal: An academic paper on GTD that lays a foundation for what I think is the biggest return on investment for GTD: reducing cognitive stress and overload. No less important, the authors provide an extremely concise and on-point summary of Allen's method, including a comprehensive (wait for it) [[https://www.researchgate.net/profile/Francis-Heylighen/publication/222552899/figure/fig1/AS:304772235186176@1449674771358/a-flowchart-depicting-the-GTD-process-for-organizing-and-processing-incoming-stuff.png][flowchart of the algorithm]]! Recommended reading.
- [[https://www.edwardslingerland.com/trying-not-to-try][Trying Not To Try]] by Edward Slingerland: This trade book is very thought provoking if you have interest in the convergence of history, culture, religion, and creativity. Of most relevance here is the connection to "flow state". Every section of Slingerland's book got me thinking about my own creativity, workplace and historical bias, and where I fit on the spectrum between Confucius and Laozi. /Wu-wei/ ftw!
- [[https://www.youtube.com/watch?v=VcgjTEa0kU4][Org Mode Basics]] and [[https://www.youtube.com/watch?v=PNE-mgkZ6HM][Organize Your Life with Org Mode]] (videos): [[https://systemcrafters.cc/][System Crafters]] is a great source of live code videos and one of the best ways to get into Emacs.

** Emacs Config
If you're interested in my detailed Emacs config, i.e., ~init.el~ you can find my setup in my [[https://github.com/rmorison/dotfiles][GitHub dotfiles repo]]. My Org-mode config started with [[https://www.youtube.com/watch?v=PNE-mgkZ6HM][Organize Your Life with Org Mode]]. If you're new to Emacs or Org-mode, start there.
  
** A Walk-through
The rest of this doc is a walk-through with animated GIFs to illustrate.

*** It All Starts with a Meeting
Let's start with a meeting, which was my original use-case. Alt-tab to Emacs, then ~C-c c m~ to open an entry in ~meetings.org~ from the [[https://github.com/rmorison/dotfiles/blob/main/org/templates/meeting.org][meeting template]]. The template will ask who the meeting is with and what it's about. (There's also a 1-on-1 meeting template, with just the "who?" question, ~C-c c 1~.)

#+CAPTION: Fave Music meeting with Lunis and Lucy
[[./img/new-meeting.gif]]

When the meeting is over and I'm ready to finish the capture I'd normally hit ~C-c C-c~. Instead, I'll use ~C-u C-u C-c C-c~ to /follow/ the capture buffer into the filed location in ~meetings.org~. I'll add a ~TODO~ manually, without a template, by typing ~M-enter~ to open a new outline node and then ~TODO Learn Für Elise on piano~. Text files ftw!

#+CAPTION: File the meeting, create a task 
[[./img/file-meeting.gif]]

*** Check the Backlog, Schedule the Task
~C-c a a~ brings up my agenda for the week. It's empty right now, nothing scheduled. ~C-c a b~ brings up my backlog view. I'll I see the "Learn Für Elise on piano" todo. Using GTD practice, I can either do this right away (2m rule, iirc) and make it DONE, move it to NEXT state, or realize it's too big for a single task and break it up.
#+CAPTION Agenda check
[[./img/check-backlog.gif]]

*** My Algorithm
Now's a good time to highlight the tasks states I use and my typical path through them.
#+begin_src mermaid :file img/task-state-cover.png
stateDiagram-v2
BREAKDOWN: BREAKDOWN-PLAN
INPROGRESS: IN-PROGRESS
HELDBLOCKED: HELD-BLOCKED
WONTDO: WONT-DO
WONTDOPROJECT: WONT-DO
state if_project <<choice>>
state getter_done <<choice>>
state last_mile <<choice>>
state plan_project <<choice>>
[*] --> TODO
TODO --> if_project
if_project --> NEXT: sized and timely
if_project --> BREAKDOWN: too bigga eat
if_project --> WONTDO: not happening
state BREAKDOWN {
  plan_project --> PLANNED: create project tasks
  plan_project --> WONTDOPROJECT: abandon project
  PLANNED --> [*]
  WONTDOPROJECT --> [*]
}
NEXT --> getter_done
getter_done --> INPROGRESS: it's alive!
getter_done --> DELEGATED: tracking
getter_done --> WONTDO: thought so, but no
INPROGRESS --> last_mile
last_mile --> DONE: yay!
last_mile --> WONTDO: changed my mind
last_mile --> HELDBLOCKED: blocked
HELDBLOCKED --> INPROGRESS: unblocked
HELDBLOCKED --> WONTDO: give up
DONE --> [*]
WONTDO --> [*]
#+end_src

#+RESULTS:
[[file:img/task-state-cover.png]]

*** Review Backlog, Schedule Work
~C-c a b~ into my backlog view, I realize my task is a project, too big on its own. (I try to visit the backlog at least once a day.) I'm going to set the task to ~BREAKDOWN-PLAN~. (For example, I have to get a keyboard, buy the sheet music, hire a music teacher) and schedule the planning work for tomorrow.

In the backlog view cursor to the "~TODO~ Learn Für Elise on piano", use ~C-c C-t~ and choose the new state with ~b~. Then, ~C-c C-s~ brings up the calendar. ~S-→~ navigates the calendar. I'll finish with ~C-c a a~ to double check my agenda.
[[./img/schedule-planning.gif]]

*** Check Agenda, Plan Project
Later, I'll check my agenda, ~C-c a a~, arrow down to the ~BREAKDOWN-PLAN~ task, hit ~ENTER~ to jump to the task. I'll drop ~TODO~ entries right under that in the outline. I'll change that ~BREAKDOWN-PLAN~ state to ~PLANNED~, then ~C-x C-s~ to save.
[[./img/plan-project.gif]]

*** Refile Into Projects File, Set Deadlines, Tee up Tasks
Refile is the gem of Org-mode. I don't want to track and annotate my project in my meetings folder, that's not the way. I'm going to move the whole project outline to my projects folder.

~C-x C-f meetings.org~ to open my meetings file, arrow to the ~PLANNED~ project, and ~C-c C-w~ to invoke Org-mode refile. 
[[./img/refile-project.gif]]

*** Prep and Schedule my Backlog
Next, I'll set deadlines and move tasks to ~NEXT~ state. ~C-c a b~ to the backlog, ~C-c C-t n~ for ~NEXT~ state and ~C-c C-d~ to set deadlines, ~C-c C-s~ for scheduled dates. Then I hand edit the "Practice Weekly" task scheduled date for a 1 week [[https://orgmode.org/manual/Repeated-tasks.html][repeated task]]. (Either you love text files, or you don't.)
[[./img/schedule-backlog.gif]]

*** Add Reference Note, Link it in Project
Finally I'll take some historical notes about Für Elise and put a link to those notes into the project outline. I open a reference note with ~C-c c n~ and save it with ~C-u C-u C-c C-c~. The template asks for a title, then I can tap in text. I've bound ~C-c l~ to save an "anchor link" at the current point, and can then open ~projects.org~ and use ~C-c C-l~ to paste it in.
[[./img/note-taking.gif]]

** Features, Features, and more Features
Emacs Org-mode has a dizzying array of [[https://orgmode.org/features.html][features]] and this walk-through is only meant to capture the essence of how I org. I don't use all of these, but for reference, here goes...
- [[https://orgmode.org/manual/Tags.html][Tags]]
- [[https://orgmode.org/manual/Tracking-your-habits.html][Habits]]
- [[https://orgmode.org/manual/Clocking-Work-Time.html][Time tracking]]
- [[https://orgmode.org/worg/org-contrib/babel/][Executing code blocks (Babel)]]
- [[https://orgmode.org/manual/Exporting.html][Exporting]] (say, to markdown or HTML) and [[https://orgmode.org/manual/Publishing.html][publishing]]
- [[https://orgmode.org/worg/org-blog-wiki.html][Blogging and content sites]]

And of course, we're talking Emacs here. If you can code it in Elisp, you can do it.

* DONE Sprint 0.5: Planning a New Service Build
CLOSED: [2022-08-27 Sat 01:06]
:PROPERTIES:
:EXPORT_FILE_NAME: sprint-zero-point-five
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '("Software architecture" "Project management")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "Sprint 0.5: uncovering the hidden work in a new service build"
:EXPORT_HUGO_ALIASES: sprint-0
:END:

** The Sprint 0.5 Scenario
I often come across new, [[https://en.wikipedia.org/wiki/Greenfield_project][greenfield]] backend projects or [[https://en.wikipedia.org/wiki/Brownfield_(software_development)][brownfield]] rewrites of an existing service (usually a monolith) into a new service architecture (usually microservice), and a new infrastructure (cloud migration). It's common---and a best practice---to kick off such a project with a [[https://en.wikipedia.org/wiki/Application_discovery_and_understanding][discovery phase]], unless product requirements are already developed and well understood by the implementation team. The discovery phase is sometime called "Sprint 0", though it's often a much bigger time and effort investment than a common development sprint.

It's also common to invest in some technical architecture and project planning during that discovery sprint. What I've observed in some projects is the technical planning in discovery is just enough for a modicum of work breakdown and estimation. Discovery typically delivers just enough design documentation for feature build tickets or story tasks. However, and especially for a greenfield build, all that planning leaves a host of implementation questions hanging.

Are we set on language, libraries, and web stack? Have we agreed on code formatters, linters, static checkers? What are we using for CI/CD? Do we have a devops plan, to write infrastructure code and bring up multiple environments? And so on.

Sometimes, when an experienced team implements in a familiar organization with established practices, these questions are mostly answered. More often, work such as this creates huge friction in the early sprints and divergence across teams working on different services. And even for the ready-to-roll team, it's worth going through a checklist, look for upgrade opportunities.

The pressure to, "Get going with delivery", can be heavy.  But resist!…if there's a load of these non-recurring tasks hanging unresolved. Get them scheduled in, with full visibility.

I call this /Sprint 0.5/ work: [[https://en.wikipedia.org/wiki/Non-recurring_engineering][NRE]] that has to be done, is better done at the beginning, and creates friction, disorganization, and divergence complexity of not done up front.

** Refine the Architecture, Revisit the Plan
When discovery phase technical architecture, planning and estimation is done, I believe it's worth coming back to at the end of Sprint 0.5. The team has a lot more "feel" for the implementation at this point and is likely to do a deeper dive into tickets and more accurate estimates.

Or, better yet, only do the top level architecture and project breakdown, with minimal [[https://asana.com/resources/t-shirt-sizing][t-shirt size]] accuracy estimation during discovery. Save the deep dive until the tech work of Sprint 0.5 is done.

Of course, commitment to stakeholders, budget and deadline pressure may make this untenable. But at least validate your discovery project plan and estimates. And if Sprint 0.5 estimates are significantly greater than those from discovery, well that's another problem.
[[./img/brown_and_black_turtle_on_brown_sand-scopio-01f822e0-47d5-4952-b881-2331aa99c598.jpg]]

** Sprint 0.5 Project Breakdown
Here I offer a canonical work breakdown for a sprint 0.5. The epics breakdown are part of a more detailed breakdown in this [[https://docs.google.com/spreadsheets/d/1VmFfYiROtW4wktL4Exlz9NODEgOy4tTJb9lJS5lP9EE/edit?usp=sharing][Sprint 0.5 project breakdown]] Google sheet.

+---------------------------+----------------------------------------------------------------+
|Epic                       |Tasks                                                           |
+---------------------------+----------------------------------------------------------------+
|Service stack template(s)  |Select language, libraries, web stack for service and serverless|
|                           |implementations; build out a "cookiecutter" template project;   |
|                           |add standardized test runner, coverage, linters, static         |
|                           |checkers, and formatters.                                       |
+---------------------------+----------------------------------------------------------------+
|Continuous integration (CI)|Decide on CI (Jenkins, GH Actions, BB Pipelines, Travis,        |
|                           |CircleCI); setup servers and/or runners; containerize template  |
|                           |service(s); add test, lint, format to CI; add Dockerfile, CI to |
|                           |templates                                                       |
+---------------------------+----------------------------------------------------------------+
|Cloud infrastructure       |Build an environment in infrastructure with template service(s):|
|                           |container strategy (orchestration, etc), networking, databases, |
|                           |proxies, load balancers; implement with infrastructure code and |
|                           |validate with env spinup                                        |
+---------------------------+----------------------------------------------------------------+
|Continuous deployment (CD) |Establish branch/release/env SDLC strategy; connect service     |
|                           |builds with env deploys                                         |
+---------------------------+----------------------------------------------------------------+
|Logging & monitoring       |Setup logging, APM, trace in service stack and feed to central  |
|                           |logging; setup service health checks; add anomaly alerting      |
|                           |(Slack, SMS, Pagerduty)                                         |
+---------------------------+----------------------------------------------------------------+
|Service architecture       |Design entities, APIs, async tasks, etc. for initial set of     |
|                           |services, including registration/authentication                 |
+---------------------------+----------------------------------------------------------------+
|Planning & estimating      |Use architecture level design for implementation stories,       |
|                           |estimates, and scheduling                                       |
+---------------------------+----------------------------------------------------------------+
|Initial build: sprint 1,2,…|At this point each service can drop a code template with CI/CD  |
|                           |ready to go and start a sequence of delivery sprints            |
+---------------------------+----------------------------------------------------------------+

** A Sprint 0.5 Gantt Chart
As a practical matter of efficiency, much of Sprint 0.5 can be split among software architects, developers, and devops staff, allowing work in parallel, as suggested below.

#+begin_src mermaid :file img/sprint-0.5-gantt.png
gantt
    title Sprint 0.5 Project Plan
    dateFormat DD
    axisFormat %d
    section Discovery
    Discovery           :discovery, 01, 2d
    section Sprint 0.5
    Service stack template(s) :templates, after discovery, 1d
    Continuous integration (CI) :ci, after templates, 1d
    Cloud infrastructure :infra, after discovery, 2d
    Continuous deployment (CD) :cd, after infra, 1d
    Logging & monitoring :logging, after cd, 1d
    Service architecture :arch, after ci, 1d
    Planning & estimating :planning, after arch, 1d
    Sprint 0.5 complete :milestone, after planning
    section Delivery
    Sprint 1 :sprint1, after planning, 1d
    Sprint 2 :sprint2, after sprint1, 1d
#+end_src

* DONE Bringup up Backstage (with Docker Compose)
CLOSED: [2023-01-01 Sun 19:22]
:PROPERTIES:
:EXPORT_FILE_NAME: bringing-up-backstage
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '("Backstage" "Software architecture" "Docker")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "How to host a backstage.io instance with Docker compose"
:END:
** Backstage (for people in a hurry)
*** Motivation
This how-to covers a relatively lightweight hosting for [[https://backstage.io/][Backstage]], Spotify's open source developer portal.
[[./img/black_and_gray_audio_mixer-scopio-243550cf-d8ba-4858-ac48-89a1eaa7681e.jpg]]

Many of the challenges that emerge as an engineering team scales--from 5 to 15, then 15 to 50, just about every factor of 2 or 3--can be traced back to something that could have been done better in a previous stage. Those challenges include documentation, architecture, code layout, and, CI/CD practice, to name a few. As deficiencies in these are identified in past work they get lumped into the [[https://en.wikipedia.org/wiki/Technical_debt][tech debt]] basket.

Does Backstage really help promote good engineering and beat back tech debt before it happens? I'm still at an experimental, proof of concept stage with Backstage, and hope to tackle that question in future articles.
*** The Problem
The [[https://backstage.io/docs/overview/what-is-backstage][Backstage docs]] are extensive, but hard to follow. Those docs jump back and forth between local configuration, plugin setups, plugin options, deployment suggestions, and more. I characterize the Backstage docs as everything, everywhere, all over the place! Maybe it's just me?

Yes, there's a [[https://demo.backstage.io/catalog?filters%5Bkind%5D=component&filters%5Buser%5D=owned][Backstage demo site]] for a quick look. The [[https://backstage.io/docs/getting-started/][Backstage getting started]] section walks through bringing up a site locally. But collaboration is what Backstage is all about; I need a shared instance to really kick the tires. (There are excellent hosted service options, such as [[https://roadie.io/][Roadie]], if you have the budget.)

So, what if you want to bring up Backstage for a small team, open source project, or a hackathon? I could not find a quick and easy setup for Backstage, something with modest effort before a =docker compose up= brings joy. The [[https://backstage.io/docs/deployment/][Backstage Deployment]] docs amount to helpful, but incomplete notes for bringing up a shared instance.
** Scope
This document walks through a Docker Compose setup for Backstage with its core features:  [[https://backstage.io/docs/features/techdocs/techdocs-overview][TechDocs]], [[https://backstage.io/docs/features/software-catalog/software-catalog-overview][Software Catalog]], and [[https://backstage.io/docs/features/software-templates/software-templates-index][Software Templates]]. In particular, the only infrastructure assumption is a publicly accessible, Docker ready server (AWS EC2, Digital Ocean, bare metal, etc.).

In this setup there is no TechDocs reliance on cloud storage; TechDocs will be stored in a shared Docker volume and published from a CI workflow, analogous to [[https://backstage.io/docs/features/techdocs/configuring-ci-cd][Backstage's cloud storage]] recommended practice.
** Tl;Dr
If you're /really/ in a hurry and already familiar with building Backstage, head over to my [[https://github.com/rmorison/backstage-docker][backstage-docker]] repo. You can likely stitch things together from the minimal docs there.
** What You'll Need
- A GitHub account or organization
- A server with [[https://docs.docker.com/engine/install/][Docker installed]]
- A local "developer" system 
** Step by step
We'll walk through creating a new backstage app repository, configuring it for this setup, setting up CI/CD to build the app, the server hosting, and end with publishing CI for TechDocs.
*** Prerequisites
Install and configure all of the tools for local backstage dev, per the [[https://backstage.io/docs/getting-started/#prerequisites][Backstage prerequisites]].
*** Create your app
We'll call our app ~backstage-app~. In a shell, ~cd~ to where you'd like to setup this project, and
#+begin_src shell
  npx @backstage/create-app
#+end_src
and at the ~Enter a name for the app [required]~ prompt, enter ~backstage-app~ (or another name of your choosing).

And with that, we have an app ready to run locally with ~yarn dev~. Developing on the local instance is covered in the [[https://backstage.io/docs/getting-started/configuration][Getting Started, configuring Backstage]] section. You can check your build and run locally with
#+begin_src shell
  cd backstage-app
  yarn dev
#+end_src

This article doesn't cover developing for Backstage or [[https://backstage.io/docs/plugins/create-a-plugin][Backstage plugins]]. We'll move on to production configuration, CI/CD, and hosting.
*** Create Repo and Push
This guide uses GitHub Actions for CI. Create a new repo for ~backstage-app~ with an individual or organization owner. No need for any perfunctory files (README, .gitignore, license), as we'll push our app into this repo.

[[./img/create-new-backstage-app-repo.png]]

Setup the remote in your local ~backstage-app~ repo and push the initial commit (from the create-app script):
#+begin_src shell
  git remote add origin git@github.com:your-name-here/backstage-app.git
  git branch -M main
  git push -u origin main
#+end_src
**** Make sure ~yarn.lock~ is updated
Backstage starts with an empty ~yarn.lock~ file. (If you ran ~yarn dev~ you probably filled this in.) Update and commit that file.
#+begin_src shell
  yarn build:all
  git add yarn.lock
  git commit -m 'lock js packages'
#+end_src
*** Docker Image CI
With our repo up, we can setup a Docker image CI. Backstage ships with a Dockerfile we'll use in ~packages/backend/Dockerfile~. Note the ~CMD~ at the end of the Dockerfile.
#+begin_src shell
CMD ["node", "packages/backend", "--config", "app-config.yaml", "--config", "app-config.production.yaml"]
#+end_src

Backstage will configure from ~app-config.yaml~ first and ~app-config.production.yaml~ second, the latter taking precedence. We'll edit ~app-config.production.yaml~ for our hosting.

But first, let's setup CI. We'll borrow from the [[https://github.com/backstage/backstage/blob/master/.github/workflows/deploy_docker-image.yml][Backstage repo GitHub action]], with some changes...
- remove yarn caching
- change the ~on:~ section to build on push to ~main~ branch or via [[https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#workflow_dispatch][workflow_dispatch]] (so we can trigger a build on a feature branch)
- build in ~.~ rather than ~./example-app~

Create ~.github/workflows/deploy_docker-image.yaml~, copying from [[https://github.com/rmorison/backstage-app/blob/main/.github/workflows/deploy_docker-image.yaml][deploy_docker-image.yaml]].

Add to the repo and push
#+begin_src shell
  git add .github/workflows/deploy_docker-image.yaml
  git commit -m 'Workflow: Build and push Docker image'
  git push
#+end_src

That should kick off a build.
[[./img/test-backstage-app-build-workflow.png]]

After 4-5 minutes you should see the workflow complete and can visit repo packages (look for the Packages section in the repo home screen):
[[./img/backstage-app-image-in-ghcr.png]]

*** App Config
Make the following config changes in ~app-config.production.yaml~.

**** Edit ~app~ and ~organization~
In the ~app~ seciton set ~title~ to  ~${BACKSTAGE_APP_TITLE}~ env var and ~baseUrl~ to ~https://${BACKSTAGE_DOMAIN}~.

In the ~organization~ section set ~name~ to ~${BACKSTAGE_ORGANIZATION_NAME}~.

These will be configured from Docker Compose environment settings.
#+begin_src yaml
  app:
    title: ${BACKSTAGE_APP_TITLE}
    baseUrl: https://${BACKSTAGE_DOMAIN}

  organization:
    name: ${BACKSTAGE_ORGANIZATION_NAME}
#+end_src

**** Edit ~backend~
Change the ~backend~ ~baseUrl~ and ~listen~ sections as follows, leaving the ~database~ section as is
#+begin_src yaml
  backend:
    baseUrl: https://${BACKSTAGE_DOMAIN}
    listen:
      port: '7007'
      host: '0.0.0.0'

    database:
      client: pg
      connection:
        host: ${POSTGRES_HOST}
        port: ${POSTGRES_PORT}
        user: ${POSTGRES_USER}
        password: ${POSTGRES_PASSWORD}
#+end_src

**** Edit ~catalog~
Replace the ~catalog~ section with
#+begin_src yaml
catalog:
  import:
    entityFilename: catalog-info.yaml
    pullRequestBranchName: backstage-integration
  rules:
    - allow: [Component, System, API, Resource, Location, Template, User, Group]
#+end_src
Later, you may want to come back and add standard locations for some entity types, Users and Groups for example. But keep it simple for now, until the system is up and running.

**** Edit ~techdocs~
[[https://backstage.io/docs/features/techdocs/techdocs-overview][TechDocs]] is Backstage's "docs as code" framework. TechDocs Markdown documents under a repository's ~docs~ tree and publishes it to a browsable, searchable documentation site. We'll setup CI/CD per the [[https://backstage.io/docs/features/techdocs/architecture#recommended-deployment][TechDocs recommended deployment]], except that the publish step will be replaced by secure copy to a volume in the Backstage Docker cluster, instead of cloud storage.

That means the ~techdocs~ section ~builder~ should be set to ~external~. The ~publisher~ section needs to point at a local directory path. Append the following to ~app-config.production.yaml~
#+begin_src yaml
  techdocs:
    builder: 'external'
    publisher:
      type: 'local'
      local:
        publishDirectory: ${TECHDOCS_DIR}
#+end_src
We'll setup a TechDocs publish action later.

**** Commit and Push
That's our production config. Your config should look like [[https://github.com/rmorison/backstage-app/blob/main/app-config.production.yaml][app-config.production.yaml]]; when you're ready, add, commit, and push.
#+begin_src shell
  git add app-config.production.yaml
  git commit -m "Production app config"
  git push
#+end_src
The "Build and push Docker image" action should trigger, check when done for status.

*** Update Backstage Catalog, Setup TechDocs

**** Update ~catalog-info.yaml~
The app was created with a scaffolded ~catalog-info.yaml~, which needs some edits. We'll also add TechDocs support and a simple doc to validate the build.

In the ~metadata~ section, change ~description~ to your repo description (or whatever you like).

Uncomment the ~annotations~ section. Change the ~github.com/project-slug~ to your repo path (minus the github.com part) and leave ~backstage.io/techdocs-ref~ as is (~dir:.~).

Under ~spec~ change ~owner~ to your Github id (recommended) or email. You can change this once you settle on an identity scheme, which is a topic for another day.

Your ~catalog-info.yaml~ should look like
#+begin_src yaml
  apiVersion: backstage.io/v1alpha1
  kind: Component
  metadata:
    name: backstage-app
    description: My Backstage application.
    annotations:
      github.com/project-slug: my-github-id/backstage-app
      backstage.io/techdocs-ref: dir:.
  spec:
    type: website
    owner: my-github-id
    lifecycle: experimental
#+end_src

**** Setup TechDocs
In addition to the ~backstage.io/techdocs-ref: dir:.~ in ~catalog-info.yaml~, TechDocs requires a ~mkdocs.yml~. Add that file to the top of your repo with the following
#+begin_src yaml
  site_name: 'backstage-app'

  nav:
    - Home: index.md

  plugins:
    - techdocs-core

  markdown_extensions:
    - markdown_inline_mermaid
#+end_src

Add some documentation, create ~docs/index.md~ with
#+begin_src markdown
  # Hello World!

  ```mermaid
  sequenceDiagram
      Alice->>John: Hello John, how are you?
      John-->>Alice: Great!
      Alice-)John: See you later!
  ```	
#+end_src

**** Commit and Push
#+begin_src shell
  git add catalog-info.yaml mkdocs.yml docs
  git commit -m "Update catalog-info, add TechDocs"
  git push
#+end_src

*** Docker Compose Setup
With our Docker image built, time to get it running on a server. We'll use the ~docker-compose.yml~ I've built in the [[https://github.com/rmorison/backstage-docker][backstage-docker repo]]. The configuration instructions are documented there, so we'll just mimic the [[https://github.com/rmorison/backstage-docker#step-by-step][Step by Step]] here. Be sure to review [[https://github.com/rmorison/backstage-docker#env-docs][env setup]] carefully, most problems trace back to a setting in that file.

On your server
#+begin_src shell
  git clone https://github.com/rmorison/backstage-docker.git
  cd backstage-docker
  cp sample.env .env
  vi .env
  sudo apt install --yes apache2-utils
  htpasswd -bn backstage change-this-password >>.htpasswd
#+end_src

Before you bring up your server, be sure to point a domain name at your server's public IP address. The Let's Encrypt ssl cert validation will fail if you don't.

With that done,
#+begin_src shell
  docker compose up --build
#+end_src
and try accessing your new server from a browser.

Test your new backstage by adding the backstage-app component: hit "Create...", then "REGISTER EXISTING COMPONENT", then enter the url to your ~catalog-info.yaml~ file.
[[./img/register-existing-component.png]]

If all is good, you should have a registered backstage component, like
[[./img/backstage-app-component.png]]

However, if you click on the "VIEW TECHDOCS" link, you'll get an error.
[[./img/techdocs-someone-dropped-the-mic.png]]

Adding our component doesn't automatically publish its TechDocs, since we've chosen an external builder (in ~app-config.production.yaml~), so that's on us.

Next, we'll setup a Github Action to publish to our compose cluster.

*** TechDocs Publish CI

The external builder setting in ~app-config.production.yaml~ is the Backstage recommended practice. But that means each repo with TechDocs needs a publish CI setup. We'll create a ~techdocs.yaml~ workflow, fashioned after [[https://backstage.io/docs/features/techdocs/configuring-ci-cd#example-github-actions-ci-and-aws-s3][Example: GitHub Actions CI and AWS S3]]. We'll replace AWS S3 storage with an ~scp~ and swap out the PlantUML support, in favor of [[https://mermaid.js.org/#/][MermaidJS]]. (Mermaid is a diagramming tool that is also [[https://github.blog/2022-02-14-include-diagrams-markdown-files-mermaid/][supported in Github Markdown rendering]].) Note that Backstage's [[https://backstage.io/docs/features/techdocs/how-to-guides#how-to-add-mermaid-support-in-techdocs][How to add Mermaid support in TechDocs]] procedure uses a separate [[https://kroki.io/][Kroki]] server, which we don't follow here, favoring a simpler "full static" approach.

Create ~.github/workflows/techdocs.yaml~, and copy in the contents of this [[https://github.com/rmorison/backstage-app/blob/main/.github/workflows/techdocs.yaml][techdocs.yaml]].

The one workflow step to note---and the most common source of errors---is the "Publish docs site via scp" step. The Docker cluster has a SSH service running on port 2222, which needs to be open on the firewall to your server. That SSH service can write to the Docker volume where Backstage looks for TechDocs, if you recall the ~techdocs~ section of our config. (That OpenSSH server is configured [[https://github.com/rmorison/backstage-docker/blob/main/docker-compose.yml#L62][here]] in the compose file, in case you're looking.)
#+begin_src yaml
      - name: Publish docs site via scp
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.TECHDOCS_HOST }}
          key: ${{ secrets.TECHDOCS_SSH_PRIVATE_KEY }}
          username: techdocs
          port: 2222
          source: site
          target: /techdocs/${{ env.ENTITY_NAMESPACE }}/${{ env.ENTITY_KIND }}/${{ env.ENTITY_NAME }}
          strip_components: 1
          rm: true
#+end_src
Note the two secrets. These go in your Github repo action secrets. ~TECHDOCS_HOST~ is the domain name pointing at your server.

If you followed the [[https://github.com/rmorison/backstage-docker#techdocs-publish-ssh-keypair][TechDocs Publish SSH Keypair]] section you already have the private key. (If not, do that now, and update your ~.env~ with the *public* key, restart your cluster.) The ~TECHDOCS_SSH_PRIVATE_KEY~ in your repo actions secrets gets the contents of the private key file, ~techdocs_rsa~. 

And finally, note ~target:~. This value has to be just right for Backstage to find TechDocs. In particular, ~ENTITY_KIND~ must be lower case, which you'll see a previous action step for.

With that, commit, push, watch the action run, and try "VIEW TECHDOCS" again.
#+begin_src shell
  git add .github/workflows/techdocs.yaml
  git commit -m 'Workflow: Publish docs site via scp'
  git push
#+end_src

If all goes well...
[[./img/techdocs-works-yay.png]]

If not, it's time to debug.
** Are we done yet?
Backstage absolutely has a cost of ownership. The goal of this article is to make quick self hosting palatable for small projects and teams. If a Backstage adoption is successful and the team or scope grows, maintaining and evolving Backstage is a full time job. Again, there are excellent hosted versions, like [[https://roadie.io/][Roadie]], if you have a budget.

Is the value proposition worth it? That's a topic for another day.
** Pulling a New Backstage Build
Standard Docker stuff, but for reference
#+begin_src shell
  docker compose stop backstage \
      && docker compose rm -f backstage \
      && docker compose pull backstage \
      && docker compose up -d backstage
  docker compose logs -f backstage
#+end_src
** Questions or Issues?
Post in [[https://github.com/rmorison/backstage-app/discussions][backstage-app discussions]] or [[https://github.com/rmorison/backstage-docker/discussions][backstage-docker discussions]].
* DONE Tame the Viper: Golang CLI Settings with Cobra & Viper
CLOSED: [2023-04-16 Sun 21:55] SCHEDULED: <2023-04-13 Thu>
:PROPERTIES:
:EXPORT_FILE_NAME: tame-the-viper
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '("Golang" "Viper" "Cobra")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "A working introduction to Cobra and Viper, a CLI configuration module for Golang apps"
:END:
** What are Cobra & Viper?
Golang comes with a [[https://pkg.go.dev/flag][flag package]] out of the box to parse garden variety command line flags. Many applications will want to use environment variables, particularly if they follow [[https://12factor.net/][Twelve-Factor App]] guidelines. The builtin [[https://pkg.go.dev/os][os package]] provides basic support. [[https://pkg.go.dev/github.com/joho/godotenv][GoDotEnv]] is a popular package with more functionality built in.

Otoh, [[https://github.com/spf13/cobra][Cobra]] & [[https://github.com/spf13/viper/][Viper]] take configuration to the next level, combining CLI flags, environment, and a config file with support for most popular formats:
- JSON, TOML, YAML, HCL, envfile and Java properties config files
  (from [[https://github.com/spf13/viper/#what-is-viper][What is Viper?]])
Viper's 45k "Imported by" stat shows the package's wide popularity among Go devs. And Cobra comes with a handy [[https://github.com/spf13/cobra-cli][Cobra Generator]] tool of it's own, to scaffold the code for new argument based CLI commands.

** The Problem with Viper...
[[./img/green_and_black_snake_illustration-scopio-35afd1bf-d3e4-4cff-8e75-c3b7b83ccf9e.jpg]]

The first and biggest blocker to using Viper is documentation. [[https://github.com/spf13/viper/blob/master/README.md][Viper's Github README]] has breadcrumbs, but Viper needs a user manual. This document aspires to that.

** What's on the Menu
We'll tackle Cobra + Viper features in three steps
1. Command line flags
2. Add environment vars
3. Marshal the config into a Go struct

All of the code examples here are in this tame-the-viper repo.

** Getting Started
*** GitHub Repo for This Guide
The code used in this guide is available in the [[https://github.com/rmorison/tame-the-viper][tame-the-viper repo]].

*** Assumptions
You'll need a working Go development environment. Go's [[https://go.dev/doc/install][Download and install]] instructions are great. Personally, I use the [[https://github.com/stefanmaric/g][stefanmaric/g]] version manager to manage my Go compilers.

This walk-through was developed with ~1.19.1~
#+begin_src shell
  ~/Projects/github.com/rmorison/tame-the-viper   main $ g list

  1.17 
  1.17.3 
  1.17.4 
  1.17.5 
  > 1.19.1 
#+end_src

*** Cobra-CLI
We'll use the handy cobra-cli to generate code for new commands. This tool saves time and provides consistent starting structure.
#+begin_src shell
  go install github.com/spf13/cobra-cli@latest
#+end_src

*** Go Mod Init
If you're coding along at home, you'll want to replace the Github account name here and throughout the Go imports.

We start a project with
#+begin_src shell
  mkdir tame-the-viper
  cd tame-the-viper
  go mod init github.com/rmorison/tame-the-viper
#+end_src

** Command Line Flags
*** First Steps
We're going to lay down first code with ~cobra-cli init~. Let's take a look at that tool's options with
#+begin_src shell
  cobra-cli --help
#+end_src
which gives
#+begin_src shell
  Cobra is a CLI library for Go that empowers applications.
  This application is a tool to generate the needed files
  to quickly create a Cobra application.

  Usage:
  cobra-cli [command]

  Available Commands:
  add         Add a command to a Cobra Application
  completion  Generate the autocompletion script for the specified shell
  help        Help about any command
  init        Initialize a Cobra Application

  Flags:
  -a, --author string    author name for copyright attribution (default "YOUR NAME")
  --config string    config file (default is $HOME/.cobra.yaml)
  -h, --help             help for cobra-cli
  -l, --license string   name of license for the project
  --viper            use Viper for configuration

  Use "cobra-cli [command] --help" for more information about a command.
#+end_src

We can use command line flags to set an author and license to drop into our new project , but instead lets take advantage ~cobra-cli~'s config file support. Create a ~.cobra.yaml~ file with
#+begin_src yaml
  author: Snake Charmer
  license: MIT
  useViper: true
#+end_src
Note the ~useViper~ setting. You can use Cobra without Viper, but Viper is where the real power lies. I always use them together.

Initialize your CLI project with
#+begin_src shell
  cobra-cli --config .cobra.yaml init
#+end_src
You should see
#+begin_src shell
  Using config file: .cobra.yaml
  Your Cobra application is ready at
  /home/rod/Projects/github.com/rmorison/tame-the-viper
#+end_src
and with ~ls *~
#+begin_src shell
  LICENSE  go.mod  go.sum  main.go

  cmd/:
  root.go
#+end_src

You can run
#+begin_src shell
  go mod tidy
  go run main.go
#+end_src
and see help text that you'll want to replace in the generated files:
#+begin_src shell
  A longer description that spans multiple lines and likely contains
  examples and usage of using your application. For example:

  Cobra is a CLI library for Go that empowers applications.
  This application is a tool to generate the needed files
  to quickly create a Cobra application.
#+end_src

No big deal, but it gets better.

*** Add a Command
Lets add our first command, ~walk-dogs~. The ~cobra-cli~ builds a nice stub with
#+begin_src shell
  cobra-cli --config .cobra.yaml add walkDogs
#+end_src
and you'll see a new file, ~cmd/walkDogs.go~. The ~go run main.go --help~ now shows that command
#+begin_src shell
  Available Commands:
  completion  Generate the autocompletion script for the specified shell
  help        Help about any command
  walkDogs    A brief description of your command
#+end_src

Let's look at the code generated for that new command. The top of ~cmd/walkDogs.go~ starts with
#+begin_src go
  /*
     Copyright © 2023 Snake Charmer

     Permission is hereby granted, free of charge, to any person obtaining a copy
#+end_src
That text is gratis the ~.cobra.yaml~ config file we're using. Front matter like this can be further customized per [[https://github.com/spf13/cobra-cli#configuring-the-cobra-generator][Configuring the cobra generator]]. 

Further down is the spec for our command:
#+begin_src go
  var walkDogsCmd = &cobra.Command{
          Use:   "walkDogs",
          Short: "A brief description of your command",
          Long: `A longer description that spans multiple lines and likely contains examples
  and usage of using your command. For example:

  Cobra is a CLI library for Go that empowers applications.
  This application is a tool to generate the needed files
  to quickly create a Cobra application.`,
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("walkDogs called")
          },
  }
#+end_src

One thing I typically change is the ~Use:~ value of the cobra command. The Cobra generator uses [[https://en.wikipedia.org/wiki/Camel_case][camel case]] for its command argument to support shells that have a problem with ~-~ in command strings. I don't write apps for those shells and the Unix shells I do implement for are fine with a command like ~walk-dogs~, which I prefer for readability and aesthetics.

Easy to change:
#+begin_src go
          Use:   "walk-dogs",
#+end_src
and the commands are now
#+begin_src shell
  Available Commands:
    completion  Generate the autocompletion script for the specified shell
    help        Help about any command
    walk-dogs   A brief description of your command
#+end_src

*** Add a Command Specific Flag
Viper supports "global" flags, called persistent flags, that will apply to all commands (subcommands, to be precise), and command specific flags, that can only be used with that specific command. Let's add a ~name~ flag. Go to the ~init()~ function and replace the instructive comments so the code looks like
#+begin_src go
  func init() {
          rootCmd.AddCommand(walkDogsCmd)

          // Here you will define your flags and configuration settings.

          walkDogsCmd.Flags().String("name", "Bella", "Which dog gets this walk")
          viper.BindPFlag("name", walkDogsCmd.Flags().Lookup("name"))
  }
#+end_src

The ~walkDogsCmd.Flags()~ line defines a command line flag, default value, and help text. ~viper.BindPFlag~ connects that flag to Viper's configuration map. Much more on that later.

If we ~go run main.go walk-dogs --help~ we see
#+begin_src shell
  Flags:
    -h, --help          help for walk-dogs
        --name string   Which dog gets this walk (default "Bella")
#+end_src

Back in ~walkDogs.go~ add a line to the ~Run:~ function,
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("walkDogs called")
                  fmt.Println("walking", viper.GetString("name"))
          },
#+end_src
Here, we're retrieving that config value from Viper. Try ~go run main.go walk-dogs~
#+begin_src shell
  walkDogs called
  walking Bella
#+end_src
then ~go run main.go walk-dogs --name Max~
#+begin_src shell
  walkDogs called
  walking Max
#+end_src

With the simple case covered, we can move on to what Cobra & Viper really bring to the table.

** Environment Variables
Environment variables are a widely popular choice, both for local developer and infrastructure configurations. The [[https://12factor.net/][Twelve Factor App]] helped popularized this use case.

Because we chose to include Viper in our ~cobra-cli~ init, the generator dropped the following function into ~cmd/root.go~
#+begin_src go
  // initConfig reads in config file and ENV variables if set.
  func initConfig() {
          // cfgFile code snipped...
          viper.AutomaticEnv() // read in environment variables that match
#+end_src
We'll get the the omitted config file code [[*Structured Configs: Using a Config File][later]]. It's the ~AutomaticEnv()~ we're interested in now. That binds Viper keys to environment variables, uppercased, of course. Therefore, in a ~bash~ shell we can type
#+begin_src shell
  NAME=Luna go run main.go walk-dogs
#+end_src
and get
#+begin_src shell
  walkDogs called
  walking Luna
#+end_src

Viper has more detailed control of environment variable binding, see [[https://github.com/spf13/viper#working-with-environment-variables][Working with Environment Variables]]. But ~AutomaticEnv()~ gets it done and, with a small customization handles more complex configurations, as well see next.

** Configs for Multiple Commands
Let's add a new ~feed-cats~ command.
#+begin_src shell
  cobra-cli --config .cobra.yaml add feedCats
#+end_src
and in ~cmd/feedCats.go~ change the ~Use:~ line
#+begin_src go
          Use:   "feed-cats",
#+end_src

In this case we want to feed lots of cats. Rewrite the ~init()~ function in ~cmd/feedCats.go~ to
#+begin_src go
  func init() {
          rootCmd.AddCommand(feedCatsCmd)

          // Here you will define your flags and configuration settings.

          feedCatsCmd.Flags().StringArray("names", []string{}, "Which cats to feed")
          viper.BindPFlag("cats.names", feedCatsCmd.Flags().Lookup("names"))
  }
#+end_src
The ~StringArray~ flag supports a slice of strings and to feed all those cats. Note the ~"cats.names"~ key for this flag. That introduces structure that we'll utilize below.

Update the ~Run: func~ to
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("feedCats called")
                  fmt.Println("feeding", viper.GetStringSlice("cats.names"))
          },
#+end_src
and lets feed some cats.
#+begin_src shell
  go run main.go feed-cats --names Loki --names Callie
#+end_src
outputs
#+begin_src shell
feedCats called
feeding [Loki Callie]
#+end_src

*** Structure in Environment Variables
If you try
#+begin_src shell
  NAMES=Binx go run main.go feed-cats
#+end_src
Binx doesn't get fed
#+begin_src shell
  feedCats called
  feeding []
#+end_src

We could try ~CATS.NAMES=Binx~, but that's not a valid environment variable name:
#+begin_src shell
  CATS.NAMES=Binx: command not found
#+end_src

Viper provides a rewrite rule to map structured keys to valid environment variables. Go back to ~initConfig()~ in ~cmd/root.go~ and above ~viper.AutomaticEnv()~ edit as follows
#+begin_src go
          replacer := strings.NewReplacer(".", "_")
          viper.SetEnvKeyReplacer(replacer)
          viper.AutomaticEnv() // read in environment variables that match
#+end_src
The ~NewReplacer~ + ~SetEnvKeyReplacer()~  does what you expect, replaces the ~.~ with ~_~. So now
#+begin_src shell
  CATS_NAMES=Binx,Mage go run main.go feed-cats
#+end_src
gives
#+begin_src shell
  feedCats called
  feeding [Binx,Mage]
#+end_src
Great. Or not. Let's investigate with an indispensable tool for working with Viper.

Create a new ~cmd/configTools.go~ file with
#+begin_src go
  package cmd

  import (
          "log"

          "github.com/spf13/viper"
          "gopkg.in/yaml.v2"
  )

  func yamlStringSettings() string {
          c := viper.AllSettings()
          bs, err := yaml.Marshal(c)
          if err != nil {
                  log.Fatalf("unable to marshal config to YAML: %v", err)
          }
          return string(bs)
  }

#+end_src
(Full D: comes straight off the [[https://github.com/spf13/viper#marshalling-to-string][Marshalling to string]] [sic] section in the Viper docs.)

Now, add another line to the ~Run: func~, so we have
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("feedCats called")
                  fmt.Println("feeding", viper.GetStringSlice("cats.names"))
                  fmt.Printf(yamlStringSettings())
          },
#+end_src

Now
#+begin_src shell
  CATS_NAMES=Binx,Mage go run main.go feed-cats
#+end_src
outputs
#+begin_src shell
  feedCats called
  feeding [Binx,Mage]
  cats:
    names: Binx,Mage
  name: Bella
#+end_src

Compare that to the output of
#+begin_src shell
  go run main.go feed-cats --names Binx --names Mage
#+end_src
namely
#+begin_src shell
  feedCats called
  feeding [Binx Mage]
  cats:
    names:
    - Binx
    - Mage
  name: Bella
#+end_src
See the problem? Our env var input is for one cat named ~"Binx,Mage"~, not two cats. (And that's a awful name for a cat, too.) Viper doesn't assume any format beyond "plain string" for environment values. Nor should it, there's no standard and no reason for Viper to have an opinion.

But lets say we want to support simple, comma delimited text. We'll have to do that ourselves. Update ~Run: func~ to
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("feedCats called")
                  viper.Set("cats.names", strings.Split(viper.GetString("cats.names"), ","))
                  fmt.Println("feeding", viper.GetStringSlice("cats.names"))
                  fmt.Printf(yamlStringSettings())
          },
#+end_src
and on
#+begin_src shell
  CATS_NAMES=Binx,Mage go run main.go feed-cats
#+end_src
you should see those cats feed correctly
#+begin_src shell
  feedCats called
  feeding [Binx Mage]
  cats:
    names:
    - Binx
    - Mage
  name: Bella
#+end_src

Since the parsing of env var values is on us, we can adopt whatever formatting convention we choose. JSON? Sure
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("feedCats called")
                  jsonValues := viper.GetString("cats.names")
                  var values []string
                  if err := json.Unmarshal([]byte(jsonValues), &values); err != nil {
                          fmt.Println(err, "->", jsonValues)
                          os.Exit(1)
                  }
                  viper.Set("cats.names", values)
                  fmt.Println("feeding", viper.GetStringSlice("cats.names"))
                  fmt.Printf(yamlStringSettings())
          },
#+end_src
and
#+begin_src shell
  CATS_NAMES='["Binx","Mage"]' go run main.go feed-cats
#+end_src
works.

But Houston, we have a problem.
#+begin_src shell
  go run main.go feed-cats --names Binx --names Mage
#+end_src
gives
#+begin_src shell
  feedCats called
  unexpected end of JSON input -> 
  exit status 1
#+end_src

We hit this error because ~jsonValues~ var is an empty string. Why is that?

Well, when Viper matches a key via environment variable it only knows set the value to a string. Viper has no builtin rule to parse env values. But remember our flag definition
#+begin_src go
          feedCatsCmd.Flags().StringArray("names", []string{}, "Which cats to feed")
          viper.BindPFlag("cats.names", feedCatsCmd.Flags().Lookup("names"))
#+end_src
With flags Viper builds a structured ~cats~ key of type ~[]string~.

Viper ~Get*~ functions, when asked to lookup a key of the wrong type, will simply return the default value for the requested type. That is, ~viper.GetString("cats.names")~ returns ~""~ when ~cats.names~ is a ~[]string~ instead of a ~string~. Viper also doesn't provide a direct way to know whether a key is set by default value, flag, or environment. It's possible to write code that introspects that (try Google or ChatGPT), but for now we'll apply a simple fix.
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("feedCats called")
                  jsonValues := viper.GetString("cats.names")
                  var values []string
                  if err := json.Unmarshal([]byte(jsonValues), &values); err == nil {
                          viper.Set("cats.names", values)
                          fmt.Println("cat names from env")
                  }
                  fmt.Println("feeding", viper.GetStringSlice("cats.names"))
                  fmt.Printf(yamlStringSettings())
          },
#+end_src

*** The Problem with Environment and Flag Configs
Environment and flag configurations work great as long as the information stays flat, or close to it. As configurations get more complex specifying these configs becomes a problem. We're faced with writing "one line configs", i.e., collapse JSON, YAML, etc. into a single line and dropping that into an env or flag spec. Escaping characters and line breaks for these is no fun and brittle. Easy to read YAML becomes gobbledygook in a single line.

Tl;dr is environment variables are fine for key/value pairs, where values are simple types, but brittle for structured configurations.

** Structured Configs: Using a Config File
Let's look at Viper's support for finger and eye friendly config files. As mentioned [[*What are Cobra & Viper?][above]] plays nice with most common formats. We'll use YAML here.

Good news: the ~feed-cats~ command is ready to roll for a config file as is.

In the directory, where ~main.go~ lives, create ~.tame-the-viper.yaml~ with
#+begin_src yaml
  cats:
    names:
      - Simba
      - Kitty
#+end_src

Then, with a simple
#+begin_src shell
  go run main.go feed-cats --config .tame-the-viper.yaml
#+end_src
you should get
#+begin_src yaml
  Using config file: .tame-the-viper.yaml
  feedCats called
  feeding [Simba Kitty]
  cats:
    names:
    - Simba
    - Kitty
  name: Bella
#+end_src
Easy.

*** Value Precedence
Now that we're mixing environment, flag, and config file settings, it's worth reviewing their precedence. Viper uses the following precedence order. Each item takes precedence over the item below it:
- explicit call to Set
- flag
- env
- config
- key/value store
- default
  (from [[https://github.com/spf13/viper][Why Viper?]])

*** Customize initConfig
Let's look at the config file setup. The ~cobra-cli~ put it in the ~cmd/root.go~ file.
#+begin_src go
  // initConfig reads in config file and ENV variables if set.
  func initConfig() {
          if cfgFile != "" {
                  // Use config file from the flag.
                  viper.SetConfigFile(cfgFile)
          } else {
                  // Find home directory.
                  home, err := os.UserHomeDir()
                  cobra.CheckErr(err)

                  // Search config in home directory with name ".tame-the-viper" (without extension).
                  viper.AddConfigPath(home)
                  viper.SetConfigType("yaml")
                  viper.SetConfigName(".tame-the-viper")
          }
#+end_src
The ~cfgFile~ string is a package var that will get set by the ~--config~ flag, via
#+begin_src go
          rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $HOME/.tame-the-viper.yaml)")
#+end_src
in the ~init()~ function.

Notice that if ~cfgFile~ is unset, the ~else~ branch above will look for ~$HOME/.tame-the-viper.yaml~ as the config. This behavior is from the code the ~cobra-cli~ put down, but we can change it. My preference is, rather than the homedir, default to a config file in the current working direction, typically the path where ~main.go~ is invoked from. (More of a "dotenv" behavior, fwiw.)

Change the ~else~ clause to
#+begin_src go
                  // Find cwd directory.
                  cwd, err := os.Getwd()
                  cobra.CheckErr(err)

                  // Search config in home directory with name ".tame-the-viper" (without extension).
                  viper.AddConfigPath(cwd)
                  viper.SetConfigType("yaml")
                  viper.SetConfigName(".tame-the-viper")
#+end_src
And if you want to change from YAML to TOML, JSON, dotenv, etc., this is the spot. If what you want is a traditional dotenv setup, ~"dotenv"~ in ~viper.SetConfigType~ will get that done.

Also, update the doc string in the flag spec. In the ~init()~ function, update the config flag to
#+begin_src go
          rootCmd.PersistentFlags().StringVar(&cfgFile, "config", "", "config file (default is $PWD/.tame-the-viper.yaml)")
#+end_src

Just like the "Don't commit .env files" practice, I always add the app's default config to ~.gitignore~ (assuming git)...
#+begin_src go
  .tame-the-viper.yaml
#+end_src

** Complex Configs
Above, we made the case that much beyond flat key/value settings, environment and flag configs are challenging. Let's tackle a more complex, structured config now that we have a config file to work with.

Use ~cobra-cli~ and add a new command:
#+begin_src shell
  cobra-cli --config .cobra.yaml add herdKittens
#+end_src
Change the ~Use:~ in ~cmd/herdKittens.go~ to
#+begin_src go
          Use:   "herd-kittens",
#+end_src

For this config we're going to dispense with environment and flag settings, and go straight to a config struct in Go and config file in YAML. We'll circle back on that dispensation later.

We're going to have Viper unmarshal a config from a YAML file into a Go struct. Under the import block of ~cmd/herdKittens.go~ add
#+begin_src go
  type KittenConfig struct {
          Mother string
          Father string
          Litter []struct {
                  KittenName string
                  FurPattern string
                  Gender     string
          }
  }

  var kittenConfig KittenConfig
#+end_src
and below that, at the ~Run: func~, change it to
#+begin_src go
          Run: func(cmd *cobra.Command, args []string) {
                  fmt.Println("herdKittens called")
                  if err := viper.UnmarshalKey("kittens", &kittenConfig); err != nil {
                          log.Fatalf("unable to marshal config to YAML: %v", err)
                  }
                  fmt.Printf("herding the clowder %+v\n", kittenConfig)
          },
#+end_src
Here ~viper.UnmarshalKey~ will find the top level "kittens" key in the config and write it's contents into ~kittenConfig~.

#+begin_src shell
  go run main.go herd-kittens
#+end_src
outputs
#+begin_src shell
  Using config file: /home/rod/Projects/github.com/rmorison/tame-the-viper/.tame-the-viper.yaml
  herdKittens called
  herding the clowder {Mother:Cleo Father:Jack Litter:[{KittenName: FurPattern: Gender:Male} {KittenName: FurPattern: Gender:Female} {KittenName: FurPattern: Gender:Female}]}
#+end_src

There's a problem: ~KittenName~ and ~FurPattern~ are default valued, empty strings. ~UnmarshalKey~ uses the [[https://pkg.go.dev/github.com/mitchellh/mapstructure][mapstructure]] package, so we need to help Viper with the YAML keys. Amend the ~KittenConfig~ type as follows.
#+begin_src go
  type KittenConfig struct {
          Mother string
          Father string
          Litter []struct {
                  KittenName string `mapstructure:"kitten_name"`
                  FurPattern string `mapstructure:"fur_pattern"`
                  Gender     string
          }
  }

#+end_src
and the output is now
#+begin_src shell
  Using config file: /home/rod/Projects/github.com/rmorison/tame-the-viper/.tame-the-viper.yaml
  herdKittens called
  herding the clowder {Mother:Cleo Father:Jack Litter:[{KittenName:Oscar FurPattern:Tabby Gender:Male} {KittenName:Daisy FurPattern:Bicolor Gender:Female} {KittenName:Lola FurPattern:Colorpoint Gender:Female}]}
#+end_src
...Spot on!

** Mixing Environment and Flags with Complex Configs
Yes, you can do it, as we've shown for ~feed-cats~.  There we used Viper's flag notation ~"cats.names"~ to connect to the YAML object structure. But that notation only goes so far. You might think that a flag key like ~"kittens.litter.1.kitten_name"~ would get us the first kitten's name in ~herd-kittens~, but no, Viper doesn't support that.

Another limitation affects mixing ~viper.Unmarshal~ and flags. See [[https://github.com/spf13/viper/issues/368][Binding flags as nested keys does not work #368]] in the Viper issues list. Down that thread [[https://github.com/spf13/viper/issues/368#issuecomment-1127455123][this snippet]] is offered as a workaround. I've used that patch with success.

However, consider if the use case is compelling enough to warrant the added complexity. In my case, it did for a particular project. There I added
#+begin_src go
  func UnmarshalConfigKey(key string, out interface{}) error {
          settings := viper.AllSettings()
          return mapstructure.Decode(settings[key], out)
  }
#+end_src
to the ~cmd~ package and call that instead of ~viper.Unmarshal~. 

Further travel down that rabbit hole is beyond the scope of this article.

** Wrapping up

*** Subcommands
One feature we haven't covered is subcommands. Let's say we wanted the following groups of commands:
- ~go run main.go feed cats~
- ~go run main.go feed dogs~
- ~go run main.go herd cats~
- ~go run main.go herd cattle~

We would run the following commands
#+begin_src shell
  cobra-cli add feed
  cobra-cli add herd
  cobra-cli add cats create -p 'feedCmd'
  cobra-cli add dogs create -p 'feedCmd'
  cobra-cli add cats create -p 'herdCmd'
  cobra-cli add cattle create -p 'herdCmd'
#+end_src
and proceed similarly to the above examples. The rest of this pattern is an exercise for the reader.

*** Final thoughts
Viper provides a reasonable solution CLI applications that just need traditional key/value "dotenv" support, on par with other packages. For complex configurations that push the limits of that simple model Viper brings much more to the table and can replace many lines of config crunching code.

It's fair to say Viper has wrinkles and subtleties that don't jump out of the package docs. Hopefully this article helps.

[[./img/portrait_of_woman_with_two_snakes_wrapped_around_her-scopio-b73eeac1-31fc-4229-9745-b2369af022fb.jpg]]

* DONE Proxy an iOS App to a Dev or Test Server
CLOSED: [2023-05-06 Sat 14:02]
:PROPERTIES:
:EXPORT_FILE_NAME: proxy-ios-app-to-dev-test-server
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '("QA & Test" "Backend Dev" "Networking")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "How to get a mobile app with hard wired API urls to talk to a dev or test server with mitmproxy"
:END:

[[./img/grayscale_photo_of_street_sign-scopio-7b8bd990-d4d6-4895-9673-d80afd80a853-cropped.jpg]]

** DISCLAIMER
This procedure describes a configuration that carries some security risk. In fact, most local developer environments host a variety of security risks: locally stored passwords and keys, production data, proprietary source code and secrets, etc. If you're working on a proprietary project you should confirm with your IT or InfoSec department that running a local Man-in-the-Middle proxy is allowed. Read [[https://en.wikipedia.org/wiki/Man-in-the-middle_attack][Man-in-the-middle attack]] to understand why all this mitm stuff keeps [[https://en.wikipedia.org/wiki/Chief_information_security_officer][CISOs]] up at night.

Finally, while the setup can be very useful and is widely shared among developers, you should absolutely not run the proxy when not in use and remove any added CA certs when there is no longer a need.

More formally:

This Man-in-the-Middle (MITM) proxy setup is provided for educational, testing, and debugging purposes only. It is not intended for any unauthorized, malicious, or unethical activities. By using this tool, you agree to take full responsibility for your actions and any consequences that may arise from using this software. The developers and distributors of this setup disclaim any liability or responsibility for any misuse, harm, or damages resulting from the use of a MITM proxy tool. Use of this tool implies that you understand and accept these terms and will not use it in any manner that violates applicable laws, regulations, or ethical standards.

** The Scenario
First, did you read the [[*DISCLAIMER][DISCLAIMER]]? Read it!

You're writing a data API backend for a mobile app. You need to devtest or debug against your locally running backend, but the app doesn't have any developer hidden settings or Easter egg, e.g., to set the API domain. Production mobile apps should *absolutely not* have any test or debug "hidden menus".

The [[https://mitmproxy.org/][mitmproxy]] app can proxy the mobile app API calls to a local server, handling https with a fake cert and CA. Setup is straightforward, but a little hard to fish out of the docs. This document is a quick how-to and might save you some and trial/error time if you've never setup a man-in-the-middle proxy before.

Note: the [[https://www.charlesproxy.com/][Charles Proxy]] also supports this setup, but I find its freemium features annoying and its documentation a little scattered, at least for this use case. Furthermore, /mitmproxy/ is open source, carefully built with security in mind, and has a very powerful custom add-on capability. Otoh, I can recommend the [[https://apps.apple.com/us/app/charles-proxy/id1134218562][Charles Proxy iOS app]], which is quite handy for sniffing traffic on your mobile device.

** How mitmproxy Works
The [[https://docs.mitmproxy.org/stable/concepts-howmitmproxyworks/][How mitmproxy works]] page is worth reading, but the essential bit is 
#+begin_quote
Mitmproxy includes a full CA implementation that generates interception certificates on the fly. To get the client to trust these certificates, we register mitmproxy as a trusted CA with the device manually.
#+end_quote

** Proxy Setup
I'll refer to your local computer, where you can run an API service for a mobile app, as /dev host/ below, and your mobile device as /iOS device/.

*** Install mitmproxy on your dev host
Installation instructions at https://docs.mitmproxy.org/stable/overview-installation/

*** Get your dev host's local IP address
It helps to know your subnet mask here, typically starting with ~192.168~, ~172.16~ or ~10.~. Your local system connects to the network with this address. Note that this address can change with time, but not often if the router (DHCP server specifically) does not get reconfigured or replaced. (If you have access, most DHCP services allow your to lock in an address for your MAC, beyond scope here.)

**** OSX and Linux with net-tools installed
Open /System Preferences/->/Network/ and select your network, look for the /IPv4 Address/ entry. Or, in a terminal
#+begin_src shell
  ifconfig | grep "inet " | grep -v 127.0.0.1
#+end_src
should show you the address you're looking for.

****  Newer versions of Linux
#+begin_src shell
  ip -4 addr | grep "inet " | grep -v 127.0.0.1
#+end_src

*** Install mitmproxy CA certs
**** Run mitmproxy
First we need to install and trust mitmproxy's fake root certificates on our iOS device and on our dev host. Mitm provides a URL that, when accessed through ~mitmproxy~, lets you download those certs. This approach is recommended, but there are [[https://docs.mitmproxy.org/stable/concepts-certificates/#installing-the-mitmproxy-ca-certificate-manually][manual installation instructions]] available if you need them.

On your dev host open a terminal and run
#+begin_src shell
  mitmproxy --listen-host 0.0.0.0 --listen-port 8080
#+end_src

***** Firewall checkpoint
If you're running a local firewall you may get an alert asking if traffic to port 8080 should be allowed. "Yes". 

If you're running ~ufw~ on Linux, that "alert" is probably in ~/var/log/auth.log~ and you'll need to run
#+begin_src shell
  sudo ufw allow from 192.168.1.0/24 to any port 8080
#+end_src
substituting you're local network mask for ~192.168.1.0/24~.

**** Point your local system at the mitmproxy
Rather than repeat something well documented on the net, a search for [[https://duckduckgo.com/?q=browser+set+manual+proxy+server&ia=web][browser set manual proxy server]] should turn up adequate instructions. You should end up at a screen similar to
[[./img/network-proxy-setup-ubuntu.png]]

Select /Manual/, enter your dev host's IP address from above as the HTTP Proxy, enter 8080 as the port. Don't select any form or authentication (if offered). If there's an /Ignore Hosts/ setting, that is completely optional. We'll only use this proxy setup one time on the dev host, to get certs, and then disable it.

**** Install CA cert on dev host
Back at a browser enter the site ~http://mitm.it/~, making sure to use ~http~ here, not ~https~. You should get this page.
[[./img/install-mitmproxys-ca.png]]

Click /Show Instructions/ and then the green /Get mitmproxy-ca-cert.pem/ button for you platform. Follow those instructions.

***** Security Note
The fine print at the bottom
#+begin_quote
Other mitmproxy users cannot intercept your connection. This page is served by your local mitmproxy instance. The certificate you are about to install has been uniquely generated on mitmproxy's first run and is not shared between mitmproxy installations.
#+end_quote
is an essential feature that keeps your CA cert unique and prevents potentially malicious hacking by others. Do not let this cert be compromised!

**** Disable the proxy on dev host
Your dev host is setup, disable the proxy from the same place you set it up.

**** Install CA cert on iOS device
The iOS device CA cert setup is analogous. I'll refer you to [[https://duckduckgo.com/?q=ios+set+manual+proxy+server&ia=web][iOS set manual proxy server]] for instructions. Make sure you use the same network that your dev host is on. You should get to this screen and enter the same /Server/ and /Port/ as your dev host.
[[./img/network-proxy-setup-ios.png]]

Open Safari and again browse to ~http://mitm.it/~, download the cert and follow the instructions, making sure you include the **Important:** step.
[[./img/install-mitmproxys-ca-ios.png]]


** Let's Go!
Now we're ready to roll!

*** Checklist
- [ ] Your local API service is up and running. I'll assume it's on port ~3000~, adjust as needed.
- [ ] Your iOS device is setup with manual proxy to your dev host on port ~8080~. (The dev host does not need to point at the proxy.)
- [ ] The iOS app you want to test with is installed on your device.

*** Map Traffic to Your Dev Host

Stop any running ~mitmproxy~ with a ~q~ command and start it back up with with the ~--map-remote~ option, replacing ~example.com~ with the domain name of the API your want to map to your dev host. 
#+begin_src shell
  mitmproxy --map-remote '|https://example.com|http://localhost:3000'
#+end_src
If there are multiple APIs, use multiple ~--map-remote~ options. Or, you can edit the ~map_remote~ setting while the proxy is running with the ~O~ command, click or arrow down to ~map_remote~, hit ~ENTER~ to edit, ~ESC~ to finish, and ~q~ to return to the options list. (One more ~q~ to return to the /Flows/ screen.)
[[./img/edit-map-remote.png]]

*** Try It Out
Start your app on your iOS device. Requests to the mapped domains should be routing to your local dev host. Verify with request logging.

** Back it Out
As mentioned, when not actively needed it is recommended to disable the proxy setup. On your dev host, just don't run ~mitmproxy~. For a permanent disable, remove your locally installed CA cert from the system. What you did in [[*Install mitmproxy on your dev host][Install mitmproxy on your dev host]], undo that.

On your iOS device un-trust the CA from /Settings/ -> /General/ -> /About/ -> /Certificate Trust Settings/. That's good enough for temporary disablement. Delete the profile for a permanent backout (/Settings/ -> /General/ -> /VPN & Device Management/.)

** Postscript

The [[https://mitmproxy.org/][mitmproxy]] program can do many other useful things for development and testing. See the [[https://docs.mitmproxy.org/stable/overview-features/][features]] section for a list of baked in capabilities. And if you need even more customization, there's an [[https://docs.mitmproxy.org/stable/addons-overview/][addon]] capability; you can write your own Python code for custom effects. The [[https://github.com/mitmproxy/mitmproxy/tree/main/examples][examples]] dir in the mitmproxy repo is full of interesting stuff. Tools for the toolbox.

[[./img/black_and_orange_metal_tool-scopio-c9c746e5-e5d0-4d47-aef3-939e85ba0104.jpg]]

* DONE Jupyter Setup with Mamba and Conda
CLOSED: [2023-05-10 Wed 16:54]
:PROPERTIES:
:EXPORT_FILE_NAME: jupyter-setup-with-mamba-conda
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '("Data Engineering" "Python" "Machine Learning")
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "A detailed, from scratch guide to Jupyter installation with Mamba and Conda for data engineering, machine learning, ..."
:END:

[[./img/2_men_in_black_and_gray_jacket_standing_on_rock_formation_during_night_time-scopio-d494b247-0a74-4382-986d-24f0d5d6e930.jpg]]

Jupyter notebooks are widely used and a great tool for interactive Python work. Notebooks are especially useful for analytics, machine learning, and scientific computing demonstrations.

** Python Packaging (in about 100 words)
There are many (many) ways to install and run Jupyter notebooks. The one given here includes some recent best practices incorporated into the [[https://mamba.readthedocs.io/en/latest/index.html][Mamba]] package manager. It's worth noting the alternatives.
1. [[https://docs.conda.io/projects/conda/en/latest/index.html][Conda]] - You'll get and use Conda with a Mamba install. In fact, it's the inspiration for Mamba: fast Conda. But you can work with Conda straight away, without Mamba, if you like.
2. [[https://pip.pypa.io/en/stable/][Pip]] - The canonical Python installer. Available [[https://www.anaconda.com/blog/using-pip-in-a-conda-environment][when the need arises]], within your Mamba / Conda install.
3. [[https://python-poetry.org/][Poetry]] - A leading choice for building Python libraries and service applications. However, since binary library dependencies are fulfilled by the operating system installation, can be a pita.
4. [[https://pipenv.pypa.io/en/latest/][Pipenv]], [[https://flit.pypa.io/en/stable/][Flit]], [[https://hatch.pypa.io/latest/][Hatch]], ... - In the Poetry camp.

** Mamba Install
The [[https://mamba.readthedocs.io/en/latest/installation.html][Mamba Installation]] page sends you right over to the [[https://github.com/conda-forge/miniforge#mambaforge][miniforge repo]] for details. There are self-extracting shell archives there, you can download and install with. Or you can ~curl~ or ~wget~ the same file. I'll use ~curl~.

#+begin_src shell
  curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh"
  bash Mambaforge-$(uname)-$(uname -m).sh
#+end_src

**** What Got Installed and How Mamba Runs
/This section is optional and covers how mamba is invoked, skip if you just want to install stuff./

It's worth taking a look at what the installer setup, insofar as how Mamba runs. Check the tail of your shell rc file. The exact file varies by shell and platform, but on Ubuntu for Bash,
#+begin_src shell
  tail -25 ~/.bashrc
#+end_src
gives
#+begin_src shell
  # >>> conda initialize >>>
  # !! Contents within this block are managed by 'conda init' !!
  __conda_setup="$('/home/me/mambaforge/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
  if [ $? -eq 0 ]; then
      eval "$__conda_setup"
  else
      if [ -f "/home/me/mambaforge/etc/profile.d/conda.sh" ]; then
          . "/home/me/mambaforge/etc/profile.d/conda.sh"
      else
          export PATH="/home/me/mambaforge/bin:$PATH"
      fi
  fi
  unset __conda_setup

  if [ -f "/home/me/mambaforge/etc/profile.d/mamba.sh" ]; then
      . "/home/me/mambaforge/etc/profile.d/mamba.sh"
  fi
  # <<< conda initialize <<<
#+end_src

If you look at the ~mamba.sh~ and ~conda.sh~ you'll notice that ~mamba~ and ~conda~ are implemented as shell functions that call programs in ~mambaforge/bin~.

This snippet from  ~mamba.sh~ is how Mamba wires up to your shell/terminal.
#+begin_src shell
  mamba() {
      \local cmd="${1-__missing__}"
      case "$cmd" in
          activate|deactivate)
              __conda_activate "$@"
              ;;
          install|update|upgrade|remove|uninstall)
              __mamba_exe "$@" || \return
              __conda_reactivate
              ;;
          ,*)
              __mamba_exe "$@"
              ;;
      esac
  }
#+end_src
The takeaway here is Mamba falls back to Conda for ~activate~ and ~deactivate~, commands we'll cover below.

Lets look at the programs that actually get invoked, after this indirection.
#+begin_src shell
  (cd ~/mambaforge/bin/ && file conda* mamba* python*)
#+end_src
outputs (slightly edited)
#+begin_src shell
  conda:             a $HOME/mambaforge/bin/python script, ASCII text executable
  conda2solv:        ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), ...
  conda-env:         a $HOME/mambaforge/bin/python script, ASCII text executable
  mamba:             a $HOME/mambaforge/bin/python script, ASCII text executable
  mamba-package:     ELF 64-bit LSB pie executable, x86-64, version 1 (GNU/Linux), ...
  python:            symbolic link to python3.10
  python3:           symbolic link to python3.10
  python3.1:         symbolic link to python3.10
  python3.10:        ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), ...
  python3.10-config: POSIX shell script, ASCII text executable, with very long lines (465)
  python3-config:    symbolic link to python3.10-config
#+end_src

Tl;dr: The installation comes with a recent version of Python, which is (or aliased to) a compiled binary program, ~python3.10~ here. Mamba and Conda themselves are Python scripts. However, Mamba's performance comes from invoking compiled binary code via libraries and it's use of an [[https://mamba.readthedocs.io/en/latest/advanced_usage/package_resolution.html][SAT package resolution algorithm]]. The [[https://github.com/mamba-org/mamba][Mamba repo]] has the implementation itself, if you're interested.

** Conda Environments
Post install, if you start a new shell or source the shell rc file cited above, e.g., ~source ~/.bashrc~ Mamba will prepend your shell prompt with an environment name in parens. If you have a fresh install that will look like
#+begin_src shell
  (base) rod@host:~$
#+end_src

It's ~(base)~ that we're looking for, the rest depends on your current shell prompt settings.

*** What's a Conda Environment?
Python, similar to many other languages, has evolved over the decades of its use. The needs of Python developers and the products they create drove an evolution in how the language was installed and run. In days of yore programmers developed a variety of ad-hoc ways to keep the Python setup for different projects from colliding. Let's say project A only worked with Python V2 and project B required Python V3. Then project C used V3, but needed a different version of, say, the Django package.

The [[https://docs.python.org/3/library/venv.html][venv]] package is now a standard part of Python to solve this problem. Long story short, it only goes part way. Many "Pure Python" libraries are in wide use, that will work on any OS. But some libraries require "binary support", meaning compiled OS specific code. The ~venv~ package doesn't fully solve this problem.

Because very often the binary component of a Python library is used for performance and access to hardware acceleration, this problem is very common problem in big data, machine learning, and scientific computing spaces. The developers in these fields saw the need for a holistic Python virtual environment solution.

That then is the key differentiator between an "old school" Python virtualenv and a Conda environment: comprehensive isolation of Python, installed libraries, /and/ their binary components.

Should you use Conda environments for everything in Python? No. The [[*Python Packaging (in about 100 words)][other solutions]] have strong use cases. But for data engineering, probably. Personally, if it's a project I'll want a Jupyter notebook for, it's Mamba ftw.

*** Best Practice: Don't install in the base env
From the [[https://mamba.readthedocs.io/en/latest/user_guide/concepts.html#base-environment][Base Environment]] section:
#+begin_quote
This is a legacy environment from ~conda~ implementation that is still heavily used.
The base environment contains the ~conda~ and ~mamba~ installation alongside a Python installation (since ~mamba~ and ~conda~ require Python to run).

~mamba~ and ~conda~, being themselves Python packages, are installed in the base environment, making the CLIs available in all activated environments based on this base environment.
#+end_quote

You'll find debate on Conda environment best practices [[https://duckduckgo.com/?q=conda+environment+best+practices&t=brave&ia=web][all over the net]]. Lets just take "leave base clean" as a given and create a new env.

** Create a "default" Conda Environment
My practice is to create a Conda environment called "default", fill it up with all the things I need for experiments, ideation, quick projects, etc. Then, if I find myself building a production project, I'll create and activate a unique environment for that.

Here, we'll just create "default". The procedure for any other environment is the same. After the create, we'll activate that environment and list what's installed in it.
#+begin_src shell
  mamba create -n default
  mamba activate default
  mamba list
#+end_src
and ~mamba list~ tells us there's nothing much there...
#+begin_src shell
  # packages in environment at /home/me/mambaforge/envs/default-demo:
  #
  # Name                    Version                   Build  Channel
#+end_src
not even a Python program, as we saw in the base environment. Isolated environments, indeed.

Let's install the latest Python, Jupyter, and Pandas, three essentials for most data work.
#+begin_src shell
mamba install python jupyterlab pandas
mamba list
#+end_src
and you should see plenty of installed packages in your env.

Type
#+begin_src shell
  jupyter-lab
#+end_src
into your terminal with the activated environment and take it from there.

For reference, the Conda [[https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#][Managing environments]] section has you covered for a wide range of environment operations.

** Final Touches
I like my default Conda environment to be ready to go at a moment's notice. I add
#+begin_src shell
  mamba activate default
#+end_src
to my ~.bashrc~. Jupyter is always just a terminal away.

* TODO Pyenv Install
#+begin_src shell
curl https://pyenv.run | bash
echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.bashrc
echo 'command -v pyenv >/dev/null || export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.bashrc
echo 'eval "$(pyenv init -)"' >> ~/.bashrc
source ~/.bashrc
#+end_src
#+begin_src shell
  sudo apt update; sudo apt install build-essential libssl-dev zlib1g-dev \
                        libbz2-dev libreadline-dev libsqlite3-dev curl \
                        libncursesw5-dev xz-utils tk-dev libxml2-dev \
                        libxmlsec1-dev libffi-dev liblzma-dev
  pyenv install 3.11
  pyenv global 3.11
  python --version
#+end_src

* NEXT The Joy of a Dedicated Server

** IPMI, power, console access

** DNS

** SSH and standard installs

*** Local
#+begin_src shell
  ssh-copy-id -i ~/.ssh/id_ecdsa root@n.morison.io
  ssh root@n.morison.io
#+end_src

*** Server
#+begin_src shell
  adduser --disabled-password rod
  cp -a .ssh /home/rod
  chown -R rod:rod ~rod/.ssh
  echo 'rod ALL=(ALL) NOPASSWD:ALL' >/etc/sudoers.d/dog && chmod 440 /etc/sudoers.d/dog
  exit
#+end_src

*** Verify access and nopw sudo
#+begin_src shell
  ssh rod@n.morison.io
  sudo cat /etc/sudoers
  sudo tail /var/log/auth.log
#+end_src
and look for
#+begin_src shell
Mar 29 00:07:39 s1254133 sshd[12673]: pam_unix(sshd:session): session opened for user rod(uid=1000) by (uid=0)
Mar 29 00:07:39 s1254133 systemd-logind[847]: New session 22 of user rod.
Mar 29 00:07:39 s1254133 systemd: pam_unix(systemd-user:session): session opened for user rod(uid=1000) by (uid=0)
Mar 29 00:07:44 s1254133 sudo:      rod : TTY=pts/1 ; PWD=/home/rod ; USER=root ; COMMAND=/usr/bin/cat /etc/sudoers
#+end_src

*** Change hostname
#+begin_src shell
  sudo hostname n.morison.io
  sudo vi /etc/hostname /etc/hosts
#+end_src
Replace the hostname in ~/etc/hostname~ and append the list in ~/etc/hosts~.

*** Create an ssh key for the non-root user
#+begin_src shell
  ssh-keygen -t ecdsa
#+end_src
Passphrase optional.

*** Install ufw
#+begin_src shell
  sudo ufw allow OpenSSH
  sudo ufw enable
#+end_src

*** Update, Upgrade, Standard Installs
#+begin_src shell
  sudo apt update && sudo apt upgrade --yes
  sudo apt install emacs-nox --yes
#+end_src

*** Docker
1. Per [[https://docs.docker.com/engine/install/ubuntu/][Docker on Ubuntu instructions]]. I use the [[https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository][apt repository]] installation, but the [[https://docs.docker.com/engine/install/ubuntu/#install-using-the-convenience-script][convenience script]] is a recommended alternative.
2. I run Docker as non-root. If you don't want to ~sudo~ all your Docker commands, follow the [[https://docs.docker.com/engine/install/linux-postinstall/#manage-docker-as-a-non-root-user][Manage Docker as a non-root user]] guide

** Modoboa
https://upcloud.com/resources/tutorials/install-secure-private-email-server-modoboa

* NEXT SAM HTTP Stack

* TODO Running TechDocs locally
When writing docs it's often desirable to see them rendered before published. The Backstage project provides a [[https://github.com/backstage/techdocs-container][techdocs-container]] that can build and serve locally, but it does not include Mermaid support. We'll run [[https://backstage.io/docs/features/techdocs/cli][techdocs-cli]] locally, outside Docker. You'll need to install [[https://www.mkdocs.org/][Mkdocs]], a Python app, with TechDocs and Mermaid support.

** TechDocs local setup requirements

- This setup assumes a Python 3 installation, [[https://github.com/pyenv/pyenv][pyenv]] recommended, but any working Python 3 setup will do.

- We'll use [[https://pypa.github.io/pipx/][pipx]] to install and extend Mkdocs. (Pipx installs Python apps each in their own virtual package environment, thus avoiding any package compatibility conflict with other Python apps.)

** Install TechDocs and Mermaid CLIs
#+begin_src shell
  npm install -g @techdocs/cli
  npm install -g @mermaid-js/mermaid-cli
#+end_src

** Install pipx with TechDocs and Mermaid support
#+begin_src shell
  pipx install mkdocs==1.*
  pipx inject mkdocs mkdocs-techdocs-core==1.*
  pipx inject mkdocs markdown-inline-mermaid==1.*
#+end_src

** Setup TechDocs in your backstage-app repo
Per [[https://backstage.io/docs/features/techdocs/creating-and-publishing#enable-documentation-for-an-already-existing-entity][Enable documentation for an already existing entity]]
- Create an ~mkdocs.yml~, including the Mermaid plugin
  #+begin_src yaml
    site_name: 'backstage-app'

    nav:
      - Home: index.md

    plugins:
      - techdocs-core

    markdown_extensions:
      - markdown_inline_mermaid
  #+end_src
- Update ~catalog-info.yaml~
  #+begin_src yaml
    metadata:
      annotations:
        backstage.io/techdocs-ref: dir:.
  #+end_src
  - Create documentation, in ~docs/index.md~
  #+begin_src markdown
    # Hello World!

    ```mermaid
    sequenceDiagram
        Alice->>John: Hello John, how are you?
        John-->>Alice: Great!
        Alice-)John: See you later!
    ```	
  #+end_src
- Serve docs
  #+begin_src shell
    techdocs-cli serve --no-docker
  #+end_src

* TODO Backstage, an Engineering Collaboration Framework

** For Management
After finally wrapping my head around Backstage, I think it's miscast. Or at least, mismarketed, to engineering managers. The problem may lie in the fact it's an engineering management tool for engineers. Engineering managers don't typically think this way: how can I make my engineers more productive when they work with other engineers in the organization.

In fact, Backstage is going to succeed where engineers---and more progressive engineering managers---buy into engineers managing up and out. The metric of success, in my opinion, the KPI if you must, is whether every engineer on every team is utilizing, contributing to, and thinking about their Backstage presence every day.

Backstage is a collaboration framework for engineering across teams. That puts backstage in a tricky position. It's core data is developed, written and maintained by engineers. However, Backstage needs support across teams for its implementation. And 

* TODO Emacs IDE FTW
:PROPERTIES:
:EXPORT_FILE_NAME: emacs-ide-ftw
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :topics '(Emacs Python Go)
:EXPORT_HUGO_CUSTOM_FRONT_MATTER+: :description "Emacs as an IDE: LSP and DAP turns Emacs into an IDE (with a little elbow grease)"
:END:
* TODO Local Hero, A Retrospective Review

** We need each other (connection)

** The egoist's life, well lived

** Urban life, challenged with alternatives

** Rustic life, wishing on a dream

** A man of faith, an African, not a Scotsman

** Born to roam
* TODO Climate References

** A Quantitative Snapshot of the Human Impact on the Planet
- [[https://www.caltech.edu/about/news/the-human-impact-on-the-environment][Press release]]
- 
- 

** Aspiration and Imperative Global Partner on High-Quality Carbon Offset Projects
- [[https://www.linkedin.com/pulse/aspiration-imperative-global-partner-high-quality-carbon-/][Press release]]
*** About Imperative Global Group, Inc.
#+begin_quote
Imperative is a mission driven, boots-on-the-ground business focused on bringing excellence to carbon offset project development and operation and on producing ultra-high quality carbon offsets. Imperative brings together multi-decade experience in carbon and conservation projects, carbon markets, major project execution and emerging market, cross-border structuring and finance. In order to drive the largest and best possible climate, sustainable development and biodiversity outcomes, Imperative is focused on emerging markets and on project types with the greatest opportunities for scale.
#+end_quote
** Expert Voices: Aspiration CEO Andrei Cherny
- [[https://www.axios.com/pro/climate-deals/2022/07/08/expert-voices-aspiration-ceo-andrei-cherny][Interview (subscriber only)]]
* TODO How to Test a Cookiecutter
